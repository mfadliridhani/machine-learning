{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to add channel dimension\n",
    "X_train = np.reshape(X_train, (60000, 28, 28, 1))\n",
    "X_test = np.reshape(X_test, (10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformIntV2 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "# Jittering: Data augmentation by random cropping and flipping\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.Resizing(28, 28),\n",
    "    keras.layers.RandomCrop(28, 28),\n",
    "    keras.layers.RandomFlip(mode='horizontal')\n",
    "])\n",
    "X_train = data_augmentation(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization: Scale pixel values from 0-255 to 0-1\n",
    "X_train = tf.cast(X_train, dtype=tf.float32) / 255.0\n",
    "X_test = tf.cast(X_test, dtype=tf.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(28,28,1)),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                              tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                              tf.keras.layers.Flatten(),\n",
    "                              tf.keras.layers.Dense(32, activation = tf.nn.sigmoid),\n",
    "                              tf.keras.layers.Dropout(0.2),\n",
    "                              tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                200736    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201,514\n",
      "Trainable params: 201,450\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Summary of the architectural model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.4249 - accuracy: 0.8882 - val_loss: 0.1777 - val_accuracy: 0.9513\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1983 - accuracy: 0.9449 - val_loss: 0.1385 - val_accuracy: 0.9610\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1553 - accuracy: 0.9548 - val_loss: 0.1202 - val_accuracy: 0.9638\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1315 - accuracy: 0.9599 - val_loss: 0.1264 - val_accuracy: 0.9612\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1170 - accuracy: 0.9646 - val_loss: 0.1096 - val_accuracy: 0.9664\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1063 - accuracy: 0.9680 - val_loss: 0.1131 - val_accuracy: 0.9663\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0957 - accuracy: 0.9702 - val_loss: 0.1114 - val_accuracy: 0.9661\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0915 - accuracy: 0.9712 - val_loss: 0.1295 - val_accuracy: 0.9608\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0842 - accuracy: 0.9740 - val_loss: 0.1079 - val_accuracy: 0.9687\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0785 - accuracy: 0.9753 - val_loss: 0.1148 - val_accuracy: 0.9665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x268e802cc40>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with early stopping\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1148 - accuracy: 0.9665\n",
      "Test accuracy: 0.9664999842643738\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.98      0.99      0.99      1135\n",
      "           2       0.93      0.96      0.94      1032\n",
      "           3       0.98      0.94      0.96      1010\n",
      "           4       0.98      0.99      0.98       982\n",
      "           5       0.93      0.97      0.95       892\n",
      "           6       0.97      0.96      0.96       958\n",
      "           7       0.97      0.95      0.96      1028\n",
      "           8       0.98      0.97      0.97       974\n",
      "           9       0.98      0.95      0.97      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 966    1    1    0    1    0    8    1    0    2]\n",
      " [   0 1126    4    0    0    2    2    1    0    0]\n",
      " [   5    1  995    9    3    4    9    4    2    0]\n",
      " [   4    2   10  949    0   37    0    3    5    0]\n",
      " [   1    2    1    0  969    0    2    0    2    5]\n",
      " [   2    0   11    3    0  864    4    6    2    0]\n",
      " [   9    3   16    1    2    8  916    0    2    1]\n",
      " [   0   10   22    3    4    7    0  977    1    4]\n",
      " [   4    2    7    4    2    3    2    1  940    9]\n",
      " [   7    1    8    1   10    4    0   14    1  963]]\n"
     ]
    }
   ],
   "source": [
    "# Print classification report and confusion matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred))\n",
    "print('\\nConfusion Matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
